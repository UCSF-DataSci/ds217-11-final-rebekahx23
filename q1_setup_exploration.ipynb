{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f08079",
   "metadata": {},
   "source": [
    "# Q1: Setup & Exploration\n",
    "\n",
    "**Phase 1-2:** Project Setup, Data Exploration  \n",
    "**Points: 6 points**\n",
    "\n",
    "**Focus:** Load data, perform initial inspection, identify data quality issues.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 1 ([`11/demo/01_setup_exploration_cleaning.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/01_setup_exploration_cleaning.ipynb)), Phases 1-2. Also see Lecture 04 (pandas I/O) and Lecture 07 (visualization).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ba25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fa7221",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Load the Chicago Beach Weather Sensors dataset, perform initial inspection, and identify data quality issues.\n",
    "\n",
    "**Note:** The datetime column in this dataset is named `Measurement Timestamp`.\n",
    "\n",
    "**Time Series Note:** Unlike the lecture's NYC Taxi data (event-based), this dataset is **time-series data** with continuous sensor readings. The data is already indexed by time, so you'll work with datetime-indexed dataframes throughout. See **Lecture 09** for time series operations. For time series visualizations, you may want to use pandas `resample()` to aggregate data (e.g., daily averages) for clearer visualization of long-term trends.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q1_data_info.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Dataset information including:\n",
    "- Dataset shape (rows × columns)\n",
    "- Column names (one per line or comma-separated)\n",
    "- Data types for each column\n",
    "- Date range (start date and end date) - **REQUIRED if temporal data**\n",
    "- Missing value counts for each column (column name: count)\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "Dataset Shape: 50000 rows × 10 columns\n",
    "\n",
    "Column Names:\n",
    "- Measurement Timestamp\n",
    "- Beach\n",
    "- Water Temperature\n",
    "- Air Temperature\n",
    "...\n",
    "\n",
    "Data Types:\n",
    "- Measurement Timestamp: datetime64[ns]\n",
    "- Beach: object\n",
    "- Water Temperature: float64\n",
    "...\n",
    "\n",
    "Date Range:\n",
    "Start: 2022-01-01 00:00:00\n",
    "End: 2027-09-15 07:00:00\n",
    "\n",
    "Missing Values:\n",
    "- Water Temperature: 2500 (5.0%)\n",
    "- Air Temperature: 1500 (3.0%)\n",
    "...\n",
    "```\n",
    "\n",
    "### 2. `output/q1_exploration.csv`\n",
    "**Format:** CSV file\n",
    "**Required Columns (exact names):** `column_name`, `mean`, `std`, `min`, `max`, `missing_count`\n",
    "**Content:** One row per numeric column in the dataset\n",
    "- `column_name`: Name of the numeric column\n",
    "- `mean`: Mean value (float)\n",
    "- `std`: Standard deviation (float)\n",
    "- `min`: Minimum value (float)\n",
    "- `max`: Maximum value (float)\n",
    "- `missing_count`: Number of missing values (integer)\n",
    "\n",
    "**Example:**\n",
    "```csv\n",
    "column_name,mean,std,min,max,missing_count\n",
    "Water Temperature,15.23,5.12,0.5,28.7,2500\n",
    "Air Temperature,18.45,8.23,-5.2,35.8,1500\n",
    "Wind Speed,6.78,4.56,0.1,25.3,0\n",
    "```\n",
    "\n",
    "### 3. `output/q1_visualizations.png`\n",
    "**Format:** PNG image file\n",
    "**Content:** At least 2 plots in a single figure (use subplots)\n",
    "**Required plots:**\n",
    "1. **Distribution plot:** Histogram or density plot of at least one numeric variable\n",
    "2. **Time series plot:** Line plot showing a numeric variable over time (if temporal data)\n",
    "\n",
    "**Requirements:**\n",
    "- Clear axis labels (xlabel, ylabel)\n",
    "- Title for each subplot\n",
    "- Overall figure title (optional but recommended)\n",
    "- Legend if multiple series shown\n",
    "- Saved as PNG with sufficient resolution (dpi=150 or higher)\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Data loaded successfully from `data/beach_sensors.csv`\n",
    "- [ ] Initial inspection completed (shape, info, head, describe)\n",
    "- [ ] Missing values identified and counted\n",
    "- [ ] Basic visualizations created (at least 2 plots: distribution + time series)\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Load and inspect the dataset** - Use standard pandas I/O and inspection methods\n",
    "2. **Parse datetime** - Identify and convert datetime column(s)\n",
    "3. **Identify missing values** - Count and calculate percentages per column\n",
    "4. **Create visualizations** - Distribution plot + time series plot (use subplots)\n",
    "5. **Save artifacts** - Write to the three required output files\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Visualization choices:** What types of plots best show your data? See Lecture 11 Notebook 1 for examples.\n",
    "- **Data quality assessment:** What issues do you see? Missing data patterns? Outliers? Inconsistent formats? Document these for Q2.\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q1, you should have:\n",
    "- [ ] Data loaded successfully\n",
    "- [ ] Basic statistics calculated\n",
    "- [ ] Initial visualizations created (2+ plots)\n",
    "- [ ] Data quality issues identified\n",
    "- [ ] All 3 artifacts saved: `q1_data_info.txt`, `q1_exploration.csv`, `q1_visualizations.png`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q2_data_cleaning.md` for Data Cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511c264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Shape: 196516 rows x 18 columns'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names:\n",
      "- Station Name\n",
      "- Measurement Timestamp\n",
      "- Air Temperature\n",
      "- Wet Bulb Temperature\n",
      "- Humidity\n",
      "- Rain Intensity\n",
      "- Interval Rain\n",
      "- Total Rain\n",
      "- Precipitation Type\n",
      "- Wind Direction\n",
      "- Wind Speed\n",
      "- Maximum Wind Speed\n",
      "- Barometric Pressure\n",
      "- Solar Radiation\n",
      "- Heading\n",
      "- Battery Life\n",
      "- Measurement Timestamp Label\n",
      "- Measurement ID\n",
      "\n",
      "\n",
      "Data Types:\n",
      "- Station Name: object\n",
      "- Measurement Timestamp: object\n",
      "- Air Temperature: float64\n",
      "- Wet Bulb Temperature: float64\n",
      "- Humidity: int64\n",
      "- Rain Intensity: float64\n",
      "- Interval Rain: float64\n",
      "- Total Rain: float64\n",
      "- Precipitation Type: float64\n",
      "- Wind Direction: int64\n",
      "- Wind Speed: float64\n",
      "- Maximum Wind Speed: float64\n",
      "- Barometric Pressure: float64\n",
      "- Solar Radiation: int64\n",
      "- Heading: float64\n",
      "- Battery Life: float64\n",
      "- Measurement Timestamp Label: object\n",
      "- Measurement ID: object\n",
      "\n",
      "\n",
      "Data Range: \n",
      "Start: 01/01/2016 01:00:00 AM\n",
      "End: 12/31/2024 12:00:00 PM\n",
      "\n",
      "\n",
      "Missing Values:\n",
      "- Station Name: 0 (0.0%)\n",
      "- Measurement Timestamp: 0 (0.0%)\n",
      "- Air Temperature: 75 (0.0%)\n",
      "- Wet Bulb Temperature: 76049 (38.7%)\n",
      "- Humidity: 0 (0.0%)\n",
      "- Rain Intensity: 76049 (38.7%)\n",
      "- Interval Rain: 0 (0.0%)\n",
      "- Total Rain: 76049 (38.7%)\n",
      "- Precipitation Type: 76049 (38.7%)\n",
      "- Wind Direction: 0 (0.0%)\n",
      "- Wind Speed: 0 (0.0%)\n",
      "- Maximum Wind Speed: 0 (0.0%)\n",
      "- Barometric Pressure: 146 (0.1%)\n",
      "- Solar Radiation: 0 (0.0%)\n",
      "- Heading: 76049 (38.7%)\n",
      "- Battery Life: 0 (0.0%)\n",
      "- Measurement Timestamp Label: 0 (0.0%)\n",
      "- Measurement ID: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Part I\n",
    "df = pd.read_csv('data/beach_sensors.csv')\n",
    "display(f\"Data Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "\n",
    "print(\"Column Names:\")\n",
    "for i in df.columns:\n",
    "    print(f\"- {i}\")\n",
    "\n",
    "print('\\n')\n",
    "print(\"Data Types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"- {col}: {df[col].dtype}\")\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Data Range: \")\n",
    "print(f\"Start: {df['Measurement Timestamp'].min()}\")\n",
    "print(f\"End: {df['Measurement Timestamp'].max()}\")\n",
    "\n",
    "print('\\n')\n",
    "print(\"Missing Values:\")\n",
    "for col in df.columns:\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    missing_percent = (missing_count / len(df)) * 100\n",
    "    print(f\"- {col}: {missing_count} ({missing_percent:.1f}%)\")\n",
    "\n",
    "#saving to output file\n",
    "with open('output/q1_data_info.txt', 'w') as f:\n",
    "    f.write(f\"Dataset Shape: {df.shape[0]} rows x {df.shape[1]} columns\\n\\n\")\n",
    "    \n",
    "    f.write(\"Column Names:\\n\")\n",
    "    for i in df.columns:\n",
    "        f.write(f\"- {i}\\n\")\n",
    "    \n",
    "    f.write(\"\\nData Types:\\n\")\n",
    "    for col in df.columns:\n",
    "        f.write(f\"- {col}: {df[col].dtype}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nDate Range:\\n\")\n",
    "    f.write(f\"Start: {df['Measurement Timestamp'].min()}\\n\")\n",
    "    f.write(f\"End: {df['Measurement Timestamp'].max()}\\n\")\n",
    "    \n",
    "    f.write(\"\\nMissing Values:\\n\")\n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_percent = (missing_count / len(df)) * 100\n",
    "        f.write(f\"- {col}: {missing_count} ({missing_percent:.1f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 2\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "exploration_data = []\n",
    "for col in numeric_cols:\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    min = df[col].min()\n",
    "    max = df[col].max()\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    exploration_data.append({\n",
    "        'column_name': col,\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'min': min,\n",
    "        'max': max,\n",
    "        'missing_count': missing_count\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(exploration_data)\n",
    "results_df.to_csv('output/q1_exploration.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded966c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output/q1_visualizations.png\n"
     ]
    }
   ],
   "source": [
    "# Part 3\n",
    "df[\"Measurement Timestamp\"] = pd.to_datetime(df[\"Measurement Timestamp\"], errors=\"coerce\")\n",
    "\n",
    "df_clean = df.dropna(subset=[\"Measurement Timestamp\"])\n",
    "\n",
    "num_col = \"Air Temperature\"\n",
    "time_col = \"Measurement Timestamp\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "fig.suptitle(\"Q1 Visualizations\", fontsize=16)\n",
    "\n",
    "sns.histplot(\n",
    "    data=df_clean,\n",
    "    x=num_col,\n",
    "    bins=30,\n",
    "    kde=True,\n",
    "    ax=axes[0],\n",
    "    color=\"lightblue\"\n",
    ")\n",
    "\n",
    "axes[0].set_title(f\"Distribution of {num_col}\")\n",
    "axes[0].set_xlabel(num_col)\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_clean,\n",
    "    x=time_col,\n",
    "    y=num_col,\n",
    "    ax=axes[1],\n",
    "    estimator=None,\n",
    "    errorbar=None,\n",
    "    lw=1,\n",
    "    color=\"purple\"\n",
    ")\n",
    "\n",
    "axes[1].set_title(f\"{num_col} Over Time\")\n",
    "axes[1].set_xlabel(\"Time\")\n",
    "axes[1].set_ylabel(num_col)\n",
    "\n",
    "# final figure\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(\"output/q1_visualizations.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved output/q1_visualizations.png\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ds217-11-final-rebekahx23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
